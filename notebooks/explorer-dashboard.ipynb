{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "from IPython.core.display_functions import display\n",
    "from IPython.display import Markdown\n",
    "from wbgapi import economy\n",
    "from wordcloud import STOPWORDS\n",
    "import altair as alt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set the display options to allow resizing columns\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "concepts_path = Path().absolute().parent / \"concepts\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "concept = \"fossil-fuels\"\n",
    "date_of_nb = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "df_concepts = pd.read_excel(concepts_path / concept / \"output_with_metadata.xlsx\")\n",
    "df_spans = pd.read_csv(concepts_path / concept / \"spans.csv\")\n",
    "date_of_nb = datetime.today().strftime(\"%d-%m-%Y\")\n",
    "df_input = pd.read_excel(concepts_path / concept / \"input.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_unfccc = pd.read_csv(concepts_path / \"unfccc_files.csv\")\n",
    "df_unfccc[\"category\"] = np.where(df_unfccc[\"party\"].notna(), \"Party\", \"Non-Party\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Contents\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Number of Documents Analysed](#number-of-documents-analysed)\n",
    "- [Geography of High-Level Concept Mentions](#geographical-distribution-of-concepts)\n",
    "- [Analysis of High-Level Concepts by Author Type (Party/Non-Party)](#high-level-analysis-of-concepts-by-author-type-party-non-party)\n",
    "    - [Total Number of Mentions](#total-number-of-mentions)\n",
    "    - [Total Number of Documents with Mentions](#total-number-of-documents-with-mentions)\n",
    "    - [Number of Unique Authors with Mentions](#number-of-unique-authors-with-mentions)\n",
    "    - [Percentage of Documents with Mentions](#percentage-of-documents-with-mentions)\n",
    "    - [Percentage of Authors with Mentions](#percentage-of-authors-mentioning-each-concept-by-party-non-party-stakeholders)\n",
    "- [Detailed Analysis of Concepts](#granular-analysis-of-concepts)\n",
    "    - [Total Mentions](#total-mentions)\n",
    "    - [Total Documents with Mentions](#total-mentions)\n",
    "    - [Total Authors with Mentions](#total-authors)\n",
    "- [Frequent Word Combinations](#word-co-occurrences)\n",
    "- [Sample Data For Mentions of Concepts](#sample-data)\n",
    "- [Annex: Methodology](#annex-methodology)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_concepts = pd.read_excel(concepts_path / concept / \"output_with_metadata.xlsx\")\n",
    "df_spans = pd.read_csv(concepts_path / concept / \"spans.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_country(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Given a text string, attempts to find the name of a country\n",
    "    mentioned in the text. Returns the name of the country if found,\n",
    "    or None otherwise.\n",
    "    \"\"\"\n",
    "    # Check for uppercase and lowercase country name\n",
    "    for country in pycountry.countries:\n",
    "        if country.name.upper() in text.upper():\n",
    "            return country.name\n",
    "        elif country.name.lower() in text.lower():\n",
    "            return country.name\n",
    "\n",
    "    # Check for common name\n",
    "    for country in pycountry.countries:\n",
    "        if country.name in text:\n",
    "            return country.name\n",
    "        if hasattr(country, \"common_name\") and country.common_name in text:\n",
    "            return country.common_name\n",
    "\n",
    "        # Check for official name\n",
    "        if hasattr(country, \"official_name\") and country.official_name in text:\n",
    "            return country.official_name\n",
    "\n",
    "        # Check for alpha_2 code (e.g., \"US\" for United States)\n",
    "        if country.alpha_2 in re.findall(r\"\\b[A-Z]{2}\\b\", text):\n",
    "            return country.name\n",
    "\n",
    "        # Check for alpha_3 code (e.g., \"USA\" for United States)\n",
    "        if country.alpha_3 in re.findall(r\"\\b[A-Z]{3}\\b\", text):\n",
    "            return country.name\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_country_code(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Given the name of a country, returns its ISO 3166-1 alpha-3\n",
    "    code. Returns None if the country is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pycountry.countries.get(name=x).alpha_3\n",
    "    except (AttributeError, LookupError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_docs_table(df_concepts):\n",
    "    # First, create a new column that categorizes each row as 'Party' or 'Non-Party'\n",
    "    df_concepts[\"category\"] = np.where(\n",
    "        df_concepts[\"Party\"].notna(), \"Party\", \"Non-Party\"\n",
    "    )\n",
    "\n",
    "    # Use groupby to count the unique document_id's for each category and for the total dataset\n",
    "    docs_analysed = df_concepts.groupby(\"category\")[\"document_id\"].nunique()\n",
    "\n",
    "    # Convert the resulting Series into a DataFrame with a single row and a custom index\n",
    "    docs_analysed_table = pd.DataFrame(\n",
    "        docs_analysed.values.reshape(1, -1),\n",
    "        columns=docs_analysed.index,\n",
    "        index=[\"Documents\"],\n",
    "    )\n",
    "\n",
    "    return docs_analysed_table\n",
    "\n",
    "\n",
    "start_col_name = \"text\"\n",
    "end_col_name = \"document_id\"\n",
    "start_col = df_concepts.columns.get_loc(start_col_name)\n",
    "end_col = df_concepts.columns.get_loc(end_col_name)\n",
    "indicator_columns = df_concepts.columns[start_col + 1 : end_col]\n",
    "# Melt the DataFrame and specify the columns to keep as id_vars\n",
    "df_concepts = df_concepts.rename(columns={\"party\": \"Party\"})\n",
    "df_concepts[\"category\"] = np.where(df_concepts[\"Party\"].notna(), \"Party\", \"Non-Party\")\n",
    "df_concepts_melted = df_concepts.melt(\n",
    "    id_vars=[col for col in df_concepts.columns if col not in indicator_columns],\n",
    "    var_name=\"Concept\",\n",
    "    value_name=\"value\",\n",
    ")\n",
    "# filter where indicators are 1\n",
    "df_concepts_melted = df_concepts_melted[df_concepts_melted[\"value\"] == 1]\n",
    "# Create a new column 'country' with the found country names\n",
    "df_concepts_melted[\"document_name_x_reformatted\"] = df_concepts_melted[\n",
    "    \"document_name_x\"\n",
    "].str.replace(r\"[_20]+\", \" \", regex=True)\n",
    "df_concepts_melted[\"document_name_y_reformatted\"] = df_concepts_melted[\n",
    "    \"document_name_y\"\n",
    "].str.replace(r\"[_20]+\", \" \", regex=True)\n",
    "df_concepts_melted[\"country_x\"] = df_concepts_melted[\n",
    "    \"document_name_x_reformatted\"\n",
    "].apply(find_country)\n",
    "df_concepts_melted[\"country_y\"] = df_concepts_melted[\n",
    "    \"document_name_y_reformatted\"\n",
    "].apply(find_country)\n",
    "df_concepts_melted[\"country\"] = df_concepts_melted[\"country_x\"].combine_first(\n",
    "    df_concepts_melted[\"country_y\"]\n",
    ")\n",
    "# create 3 letter country code\n",
    "df_concepts_melted[\"country_code\"] = df_concepts_melted[\"country\"].apply(\n",
    "    get_country_code\n",
    ")\n",
    "# create 3 letter country code\n",
    "df_concepts_melted[\"country_code\"] = df_concepts_melted[\"country\"].apply(\n",
    "    get_country_code\n",
    ")\n",
    "df_eco = pd.DataFrame(economy.list())\n",
    "# Assuming the 3-letter country code column in df_concepts_melted is named 'country_code'\n",
    "df_concepts_melted = pd.merge(\n",
    "    df_concepts_melted,\n",
    "    df_eco[[\"id\", \"region\"]],\n",
    "    left_on=\"country_code\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_documents = (\n",
    "    df_concepts_melted.groupby([\"Concept\", \"category\"])[\"document_id\"]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .pivot(index=\"Concept\", columns=\"category\", values=\"document_id\")\n",
    ")\n",
    "df_documents[\"Total\"] = df_documents.sum(axis=1)\n",
    "df_documents.columns.name = None\n",
    "df_mentions = (\n",
    "    df_concepts_melted.groupby(\"Concept\")[\"category\"]\n",
    "    .value_counts()\n",
    "    .rename(\"count\")\n",
    "    .reset_index()\n",
    "    .pivot(index=\"Concept\", columns=\"category\", values=\"count\")\n",
    ")  # .reset_index()\n",
    "df_mentions[\"Total\"] = df_mentions.sum(axis=1)\n",
    "df_mentions.columns.name = None\n",
    "df_authors = (\n",
    "    df_concepts_melted.groupby([\"Concept\", \"category\"])[\"author\"]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .pivot(index=\"Concept\", columns=\"category\", values=\"author\")\n",
    ")\n",
    "df_authors[\"Total\"] = df_authors.sum(axis=1)\n",
    "df_authors.columns.name = None\n",
    "\n",
    "# group melted df by country_code and Concept and number of concept\n",
    "dd = (\n",
    "    df_concepts_melted.groupby([\"country_code\", \"Concept\"])[\"Concept\"]\n",
    "    .count()\n",
    "    .rename(\"count\")\n",
    "    .reset_index()\n",
    ")\n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "merged = world.set_index(\"iso_a3\").join(dd.set_index(\"country_code\"), how=\"inner\")\n",
    "# where concept is nan, create new rows for all concepts with count 0\n",
    "# merged = merged.reset_index().melt(id_vars=['country', 'geometry'], value_vars=merged.columns[2:], value_name='count').dropna(subset=['count'])\n",
    "\n",
    "# get a unique mapping between document_id and document_name_y for the df_concepts_melted\n",
    "mapping = df_concepts_melted[\n",
    "    [\"document_id\", \"document_name_y\", \"category\", \"author\"]\n",
    "].drop_duplicates()\n",
    "# now apply this mapping to df_spans to create a new column with the document_name\n",
    "\n",
    "df_spans[\"processed_sentence\"] = df_spans[\"sentence\"].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in (STOPWORDS)])\n",
    ")\n",
    "df_spans[\"normalised_text\"] = df_spans[\"text\"].str.lower()\n",
    "df_spans = df_spans.merge(mapping, on=[\"document_id\"], how=\"left\")\n",
    "merged = merged.reset_index().rename(columns={\"index\": \"iso_a3\"})\n",
    "# for every country in world, check if the conc is in merged. If not, add a row with count 0\n",
    "for country in world[\"iso_a3\"]:\n",
    "    for conc in merged[\"Concept\"].unique():\n",
    "        if not merged[\n",
    "            (merged[\"iso_a3\"] == country) & (merged[\"Concept\"] == conc)\n",
    "        ].empty:\n",
    "            continue\n",
    "        else:\n",
    "            merged = pd.concat(\n",
    "                [\n",
    "                    merged,\n",
    "                    world[world[\"iso_a3\"] == country]\n",
    "                    .reset_index(drop=True)\n",
    "                    .merge(\n",
    "                        pd.DataFrame({\"Concept\": conc, \"count\": 0}, index=[0]),\n",
    "                        left_index=True,\n",
    "                        right_index=True,\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "\n",
    "merged = merged.rename(columns={\"name\": \"country\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='introduction'></a>\n",
    "# Introduction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "report_text = f\"\"\"\n",
    " This report contains summary statistics and visualisations for all identified mentions of {concept} within the Global Stocktake submissions, as of {date_of_nb}. It summarises the total number of mentions of {concept} and the number of documents these mentions come from,  broken down by Party and non-Party stakeholders. It also includes a full list of the Parties and non-Party stakeholders which mention {concept} within the Global Stocktake submissions, broken down by subtypes. A sample of the extracts where {concept} is mentioned is included below, with a link to the full set provided. The technical annex contains the methodology used to source the data for this report.\n",
    "\"\"\"\n",
    "display(Markdown(report_text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='number-of-documents-analysed'></a>\n",
    "# Number of Documents Analysed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_analysed_table = create_docs_table(df_concepts_melted)\n",
    "docs_analysed_table_melted = docs_analysed_table.reset_index().melt(\n",
    "    id_vars=[\"index\"], var_name=\"stakeholder\", value_name=\"count\"\n",
    ")\n",
    "chart = (\n",
    "    alt.Chart(docs_analysed_table_melted)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=\"index:N\",\n",
    "        y=\"count:Q\",\n",
    "        color=\"stakeholder:N\",\n",
    "        order=alt.Order(\"stakeholder:N\", sort=\"ascending\"),\n",
    "    )\n",
    "    .properties(\n",
    "        title=f\"Number of documents analysed by author type\", width=400, height=300\n",
    "    )\n",
    ")\n",
    "\n",
    "chart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='geographical-distribution-of-concepts'></a>\n",
    "# Geography of High-Level Concept Mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to create a choropleth map for a given concept\n",
    "def create_choropleth_map(merged, concept, range_min, range_max):\n",
    "    choropleth_map = (\n",
    "        alt.Chart(merged[merged[\"Concept\"] == concept])\n",
    "        .mark_geoshape(stroke=\"black\", strokeWidth=1)\n",
    "        .encode(\n",
    "            color=alt.Color(\n",
    "                \"count:Q\",\n",
    "                scale=alt.Scale(scheme=\"viridis\", domain=[range_min, range_max]),\n",
    "            ),\n",
    "            tooltip=[\"country:N\", \"count:Q\"],\n",
    "        )\n",
    "        .properties(\n",
    "            width=800, height=400, title=f\"Number of Mentions of {concept} by Country\"\n",
    "        )\n",
    "    )\n",
    "    return choropleth_map\n",
    "\n",
    "\n",
    "# Remove Antarctica\n",
    "merged = merged[merged[\"country\"] != \"Antarctica\"]\n",
    "\n",
    "# Calculate the global maximum and minimum counts across all concepts\n",
    "global_max_count = np.max(merged[\"count\"])\n",
    "global_min_count = np.min(merged[\"count\"])\n",
    "\n",
    "# Iterate over the unique concepts and create a separate choropleth map for each\n",
    "unique_concepts = sorted(merged[\"Concept\"].unique())\n",
    "for conc in unique_concepts:\n",
    "    choropleth_map = create_choropleth_map(\n",
    "        merged, conc, range_min=global_min_count, range_max=global_max_count\n",
    "    )\n",
    "    choropleth_map.display()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='high-level-analysis-of-concepts-by-author-type-party-non-party'></a>\n",
    "# Analysis of High-Level Concepts by Author Type (Party/Non-Party)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"This section provides an overview of the high-level concepts extracted (see Annex for definition of high-level), split by author type (Party/Non-Party). This includes the number of mentions of each concept, the number of documents mentioning each concept, and the number of authors mentioning each concept, as well as all of these expressed in percentages.\"\"\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='total-number-of-mentions'></a>\n",
    "## Total Number of Mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df_mentions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='total-number-of-documents-with-mentions'></a>\n",
    "## Total Number of Documents with Mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df_documents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='number-of-unique-authors-with-mentions'></a>\n",
    "## Number of Unique Authors with Mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df_authors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_percentages_stacked(df):\n",
    "    df = df.reset_index()\n",
    "    df[\"Non-Party_percentage\"] = df[\"Non-Party\"] / df[\"Total\"] * 100\n",
    "    df[\"Party_percentage\"] = df[\"Party\"] / df[\"Total\"] * 100\n",
    "\n",
    "    # Melt the DataFrame to have columns: Concept, Group, and Percentage\n",
    "    df_melted = df.melt(\n",
    "        id_vars=\"Concept\",\n",
    "        value_vars=[\"Non-Party\", \"Party\"],\n",
    "        var_name=\"Group\",\n",
    "        value_name=\"Percentage\",\n",
    "    )\n",
    "\n",
    "    base = alt.Chart(df_melted).encode(\n",
    "        x=alt.X(\"Concept:N\", title=\"Concept\"),\n",
    "        y=alt.Y(\n",
    "            \"Percentage:Q\",\n",
    "            title=\"Percentage\",\n",
    "            stack=\"normalize\",\n",
    "            axis=alt.Axis(format=\"%\"),\n",
    "        ),\n",
    "        color=alt.Color(\"Group:N\", title=\"Group\", scale=alt.Scale(scheme=\"tableau10\")),\n",
    "        tooltip=[\"Concept\", \"Group\", \"Percentage\"],\n",
    "    )\n",
    "\n",
    "    # Create the bar chart\n",
    "    bar_chart = base.mark_bar().encode()\n",
    "\n",
    "    display(bar_chart)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='percentage-of-documents-with-mentions'></a>\n",
    "## Percentage of Documents with Mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_docs = (\n",
    "    (df_concepts_melted.groupby([\"category\", \"Concept\"]).document_id.nunique())\n",
    "    .reset_index()\n",
    "    .set_index(\"category\")\n",
    ")\n",
    "unique_docs_by_type = df_unfccc.groupby(\"category\").size()\n",
    "unique_docs[\"Total\"] = unique_docs_by_type\n",
    "unique_docs[\"Percentage\"] = unique_docs[\"document_id\"] / unique_docs[\"Total\"] * 100\n",
    "unique_docs = unique_docs.reset_index()\n",
    "\n",
    "alt.Chart(unique_docs).mark_bar().encode(\n",
    "    x=alt.X(\"category:O\"),\n",
    "    y=alt.Y(\"Percentage:Q\", scale=alt.Scale(domain=[0, 100])),\n",
    "    color=\"category:N\",\n",
    "    column=\"Concept:N\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='percentage-of-authors-mentioning-each-concept-by-party-non-party-stakeholders'></a>\n",
    "## Percentage of Authors with Mentions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_authors = (\n",
    "    (df_concepts_melted.groupby([\"category\", \"Concept\"]).author.nunique())\n",
    "    .reset_index()\n",
    "    .set_index(\"category\")\n",
    ")\n",
    "unique_docs_by_type = df_unfccc.groupby(\"category\").size()\n",
    "unique_authors[\"Total\"] = unique_docs_by_type\n",
    "unique_authors[\"Percentage\"] = unique_authors[\"author\"] / unique_authors[\"Total\"] * 100\n",
    "unique_authors = unique_authors.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# of all the Party/non-Party-authors in the corpus, what percentage have documents containing mentions of each concept?\n",
    "data_authors = (\n",
    "    (\n",
    "        100\n",
    "        * df_concepts_melted.groupby([\"category\", \"Concept\"]).author.nunique()\n",
    "        / df_unfccc.groupby(\"category\").size()\n",
    "    )\n",
    "    .rename(\"Percentage\")\n",
    "    .reset_index()\n",
    ")\n",
    "# make sure chart has no x-axis labels\n",
    "chart = (\n",
    "    alt.Chart(unique_authors)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\"category:O\", axis=alt.Axis(labels=True)),\n",
    "        y=alt.Y(\"Percentage:Q\", scale=alt.Scale(domain=[0, 100])),\n",
    "        color=\"category:N\",\n",
    "        column=\"Concept:N\",\n",
    "    )\n",
    ")\n",
    "chart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='granular-analysis-of-concepts'></a>\n",
    "# Detailed Analysis of Concepts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"This section provides a detailed analysis of the concepts extracted (see Annex for full definition of detailed). Here, we do not split by\n",
    "Party/Non-Party but instead look at more granular subcategories of the meta-concepts to give a sense of which subcategories are important, potentially facilitating better search.\"\"\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "total_concept_mentions = (\n",
    "    df_spans.rename(columns={\"type\": \"concept\"})\n",
    "    .groupby([\"id\", \"concept\"])\n",
    "    .document_id.count()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"document_id\": \"count\"})\n",
    ")\n",
    "document_concept_mentions = (\n",
    "    df_spans.rename(columns={\"type\": \"concept\"})\n",
    "    .groupby([\"id\", \"concept\"])\n",
    "    .document_id.nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"document_id\": \"count\"})\n",
    ")\n",
    "author_concept_mentions = (\n",
    "    df_spans.rename(columns={\"type\": \"concept\"})\n",
    "    .groupby([\"id\", \"concept\"])\n",
    "    .author.nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"author\": \"count\"})\n",
    ")\n",
    "\n",
    "\n",
    "def plot_concept_mentions(data, title):\n",
    "    # Create a base chart\n",
    "    base_chart = (\n",
    "        alt.Chart(data)\n",
    "        .mark_bar()\n",
    "        .encode(\n",
    "            y=alt.Y(\"count:Q\", title=title),\n",
    "            x=alt.X(\n",
    "                \"id:N\", sort=\"-y\", axis=alt.Axis(title=None, labels=True), title=\"ID\"\n",
    "            ),\n",
    "            color=alt.Color(\n",
    "                \"concept:N\",\n",
    "                scale=alt.Scale(scheme=\"category10\"),\n",
    "                legend=alt.Legend(title=\"Concept\"),\n",
    "            ),\n",
    "            tooltip=[\"count:Q\"],\n",
    "        )\n",
    "        .properties(\n",
    "            width=600,\n",
    "            height=300,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Display the combined chart\n",
    "    display(base_chart)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='total-mentions'></a>\n",
    "## Total Mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_concept_mentions(total_concept_mentions, \"Total mentions of each concept\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='total-mentions'></a>\n",
    "## Total Documents with Mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_concept_mentions(\n",
    "    document_concept_mentions, \"Number of documents mentioning each concept\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='total-authors'></a>\n",
    "## Total Authors with Mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_concept_mentions(\n",
    "    author_concept_mentions, \"Number of authors mentioning each concept\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='word-co-occurrences'></a>\n",
    "# Frequent Word Combinations\n",
    "\n",
    "This section displays the most common co-occurring words for all mentions of a concept. The co-occurrence is calculated by counting the top 10 tuples and triples (\"bigrams\" and \"trigrams\") of words that appear in the same sentences as the extracted concepts. This is useful because it allows us to pinpoint related concepts that are not necessarily included in high level categories, thus providing hints for where to search for new concepts."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_ngrams(df, concept, n, text_col=\"processed_sentence\"):\n",
    "    # Filter the DataFrame for the given concept\n",
    "    concept_df = df[df[\"type\"] == concept]\n",
    "\n",
    "    # Tokenize the sentences and extract n-grams\n",
    "    tokens = [word_tokenize(sentence) for sentence in concept_df[text_col]]\n",
    "    ngram_list = [ngram for sentence in tokens for ngram in ngrams(sentence, n)]\n",
    "\n",
    "    # Filter out n-grams containing non-word characters\n",
    "    word_ngrams = [\n",
    "        ngram for ngram in ngram_list if all(re.match(r\"^\\w+$\", word) for word in ngram)\n",
    "    ]\n",
    "\n",
    "    # Calculate the frequency distribution of n-grams\n",
    "    freq_dist = FreqDist(word_ngrams)\n",
    "\n",
    "    return freq_dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "concepts = df_spans.type.unique()\n",
    "\n",
    "# Set the number of top bigrams and trigrams to display\n",
    "num_top_ngrams = 10\n",
    "\n",
    "for conc in concepts:\n",
    "    display(\n",
    "        Markdown(\n",
    "            f\"## Top {num_top_ngrams} Bigrams and Trigrams in Sentences Relating to {conc.title()}\\n\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Extract bigrams and trigrams for the given concept\n",
    "    bigrams_freq = extract_ngrams(df_spans, conc, n=2, text_col=\"processed_sentence\")\n",
    "    trigrams_freq = extract_ngrams(df_spans, conc, n=3, text_col=\"processed_sentence\")\n",
    "\n",
    "    # create a single DataFrame with the bigrams and trigrams\n",
    "    ngrams_df = pd.DataFrame(\n",
    "        bigrams_freq.most_common(num_top_ngrams), columns=[\"bigram\", \"bigram_count\"]\n",
    "    )\n",
    "    ngrams_df[\"trigram\"] = [\n",
    "        trigram for trigram, _ in trigrams_freq.most_common(num_top_ngrams)\n",
    "    ]\n",
    "    ngrams_df[\"trigram_count\"] = [\n",
    "        count for _, count in trigrams_freq.most_common(num_top_ngrams)\n",
    "    ]\n",
    "\n",
    "    # # Create DataFrames for bigrams and trigrams\n",
    "    # bigrams_df = pd.DataFrame(bigrams_freq.most_common(num_top_ngrams), columns=['Bigrams', 'Frequency'])\n",
    "    # trigrams_df = pd.DataFrame(trigrams_freq.most_common(num_top_ngrams), columns=['Trigrams', 'Frequency'])\n",
    "\n",
    "    display(Markdown(f\"### Most common ngrams\\n\"))\n",
    "    display(ngrams_df)\n",
    "    # display(Markdown(f\"### Trigrams\\n\"))\n",
    "    # display(trigrams_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='sample-data'></a>\n",
    "# Sample Data For Mentions of Concepts."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"To see the full sample of mentions of {concept}, please click [here](https://github.com/climatepolicyradar/global-stocktake/blob/main/concepts/{concept}/spans.csv) for a download link.\"\"\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "infile = pd.read_excel(\n",
    "    \"/home/stefan/PycharmProjects/global-stocktake/concepts/fossil-fuels/input.xlsx\",\n",
    "    header=[0, 1],\n",
    ")\n",
    "# get a unique mapping between document_id and document_name_y for the df_concepts_melted\n",
    "mapping = df_concepts_melted[\n",
    "    [\"document_id\", \"document_name_y\", \"category\"]\n",
    "].drop_duplicates()\n",
    "# now apply this mapping to df_spans to create a new column with the document_name\n",
    "df_spans = df_spans.merge(mapping, on=[\"document_id\"], how=\"left\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "excel_string = infile.to_csv(sep=\"\\t\", index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# , header=[0,1])\n",
    "# infile.columns = infile.columns.map(' - '.join)\n",
    "infile.columns = [\n",
    "    \" - \".join(col).strip() if \"Unnamed\" not in col[1] else col[0]\n",
    "    for col in infile.columns\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='annex-methodology'></a>\n",
    "# Annex: Methodology"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "The documents within the Global Submissions Information Portal were searched for all mentions of concepts related to the meta-concept \"{concept}\". This involved automatically translating all documents into English using the Google Translate API before identifying as many potential linguistic expressions of the meta-concept to feed in as rules for a search process. The methodology is explained in detail [here](https://www.notion.so/climatepolicyradar/Concept-tracker-a879dfc5c2fd49159838af86cd5e8955) and the relevant linguistic input file is available for download [here](https://github.com/climatepolicyradar/global-stocktake/tree/main/concepts/{concept}/input.xlsx).\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}