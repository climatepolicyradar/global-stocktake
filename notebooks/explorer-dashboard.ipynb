{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Introduction](#section-1)\n",
    "- [Analysis by author type](#section-2)\n",
    "    - [Number of mentions of each concept split by Party/non-Party stakeholders](#section-2-2)\n",
    "    - [Number of documents mentioning each concept split by Party/non-Party stakeholders](#section-2-3)\n",
    "    - [Number of authors mentioning each concept split by Party/non-Party stakeholders](#section-2-4)\n",
    "    - [Percentage of mentions of each concept by Party/non-Party stakeholders](#section-2-5)\n",
    "    - [Percentage of documents mentioning each concept by Party/non-Party stakeholders](#section-2-6)\n",
    "    - [Percentage of authors mentioning each concept by Party/non-Party stakeholders](#section-2-7)\n",
    "- [Granular Breakdown of Concepts](#section-3)\n",
    "    - [Total Documents](#section-3-1)\n",
    "    - [Total Mentions](#section-3-2)\n",
    "    - [Total Authors](#section-3-3)\n",
    "- [Geographical distribution of concepts](#section-4)\n",
    "- [Sample mentions of concepts](#section-5)\n",
    "- [Word Co-Occurrences](#section-6)\n",
    "- [Annex: Methodology](#section-7)\n",
    "- [Explanation of the linguistic rules using OpenAI GPT-4](#section-8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "from IPython.core.display_functions import display\n",
    "from IPython.display import Markdown\n",
    "from wbgapi import economy\n",
    "from wordcloud import STOPWORDS\n",
    "import altair as alt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set the display options to allow resizing columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "concepts_path = Path().absolute().parent / 'concepts'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "concept = \"fossil-fuels\"\n",
    "date_of_nb = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "df_concepts = pd.read_excel(concepts_path / concept / \"output_with_metadata.xlsx\")\n",
    "df_spans = pd.read_csv(concepts_path / concept / \"spans.csv\")\n",
    "date_of_nb = datetime.today().strftime('%d-%m-%Y')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_concepts = pd.read_excel(concepts_path / concept / \"output_with_metadata.xlsx\")\n",
    "df_spans = pd.read_csv(concepts_path / concept / \"spans.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_country(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Given a text string, attempts to find the name of a country\n",
    "    mentioned in the text. Returns the name of the country if found,\n",
    "    or None otherwise.\n",
    "    \"\"\"\n",
    "    # Check for uppercase and lowercase country name\n",
    "    for country in pycountry.countries:\n",
    "        if country.name.upper() in text.upper():\n",
    "            return country.name\n",
    "        elif country.name.lower() in text.lower():\n",
    "            return country.name\n",
    "\n",
    "    # Check for common name\n",
    "    for country in pycountry.countries:\n",
    "        if country.name in text:\n",
    "            return country.name\n",
    "        if hasattr(country, 'common_name') and country.common_name in text:\n",
    "            return country.common_name\n",
    "\n",
    "        # Check for official name\n",
    "        if hasattr(country, 'official_name') and country.official_name in text:\n",
    "            return country.official_name\n",
    "\n",
    "        # Check for alpha_2 code (e.g., \"US\" for United States)\n",
    "        if country.alpha_2 in re.findall(r'\\b[A-Z]{2}\\b', text):\n",
    "            return country.name\n",
    "\n",
    "        # Check for alpha_3 code (e.g., \"USA\" for United States)\n",
    "        if country.alpha_3 in re.findall(r'\\b[A-Z]{3}\\b', text):\n",
    "            return country.name\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_country_code(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Given the name of a country, returns its ISO 3166-1 alpha-3\n",
    "    code. Returns None if the country is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pycountry.countries.get(name=x).alpha_3\n",
    "    except (AttributeError, LookupError):\n",
    "        return None\n",
    "\n",
    "def create_docs_table(df_concepts):\n",
    "\n",
    "    # First, create a new column that categorizes each row as 'Party' or 'Non-Party'\n",
    "    df_concepts['category'] = np.where(df_concepts['Party'].notna(), 'Party', 'Non-Party')\n",
    "\n",
    "    # Use groupby to count the unique document_id's for each category and for the total dataset\n",
    "    docs_analysed = df_concepts.groupby('category')['document_id'].nunique()\n",
    "\n",
    "    # Convert the resulting Series into a DataFrame with a single row and a custom index\n",
    "    docs_analysed_table = pd.DataFrame(docs_analysed.values.reshape(1, -1),\n",
    "                                       columns=docs_analysed.index,\n",
    "                                       index=[\"Documents\"])\n",
    "\n",
    "    return docs_analysed_table\n",
    "\n",
    "start_col_name = \"text\"\n",
    "end_col_name = \"document_id\"\n",
    "start_col = df_concepts.columns.get_loc(start_col_name)\n",
    "end_col = df_concepts.columns.get_loc(end_col_name)\n",
    "indicator_columns = df_concepts.columns[start_col + 1:end_col]\n",
    "# Melt the DataFrame and specify the columns to keep as id_vars\n",
    "df_concepts = df_concepts.rename(columns={'party': 'Party'})\n",
    "df_concepts['category'] = np.where(df_concepts['Party'].notna(), 'Party', 'Non-Party')\n",
    "df_concepts_melted = df_concepts.melt(id_vars=[col for col in df_concepts.columns if col not in indicator_columns], var_name=\"Concept\", value_name=\"value\")\n",
    "# filter where indicators are 1\n",
    "df_concepts_melted = df_concepts_melted[df_concepts_melted[\"value\"] == 1]\n",
    "# Create a new column 'country' with the found country names\n",
    "df_concepts_melted[\"document_name_x_reformatted\"] = df_concepts_melted[\"document_name_x\"].str.replace(r'[_20]+', ' ', regex=True)\n",
    "df_concepts_melted[\"document_name_y_reformatted\"] = df_concepts_melted[\"document_name_y\"].str.replace(r'[_20]+', ' ', regex=True)\n",
    "df_concepts_melted['country_x'] = df_concepts_melted['document_name_x_reformatted'].apply(find_country)\n",
    "df_concepts_melted['country_y'] = df_concepts_melted['document_name_y_reformatted'].apply(find_country)\n",
    "df_concepts_melted['country'] = df_concepts_melted['country_x'].combine_first(df_concepts_melted['country_y'])\n",
    "# create 3 letter country code\n",
    "df_concepts_melted['country_code'] = df_concepts_melted['country'].apply(get_country_code)\n",
    "# create 3 letter country code\n",
    "df_concepts_melted['country_code'] = df_concepts_melted['country'].apply(get_country_code)\n",
    "df_eco = pd.DataFrame(economy.list())\n",
    "# Assuming the 3-letter country code column in df_concepts_melted is named 'country_code'\n",
    "df_concepts_melted = pd.merge(df_concepts_melted, df_eco[['id', 'region']], left_on='country_code', right_on='id', how='left')\n",
    "\n",
    "df_documents=df_concepts_melted.groupby(['Concept', 'category'])['document_id'].nunique().reset_index().pivot(index='Concept', columns='category', values='document_id')\n",
    "df_documents['Total'] = df_documents.sum(axis=1)\n",
    "df_documents.columns.name = None\n",
    "df_mentions = df_concepts_melted.groupby('Concept')['category'].value_counts().rename('count').reset_index().pivot(index='Concept', columns='category', values='count')#.reset_index()\n",
    "df_mentions['Total'] = df_mentions.sum(axis=1)\n",
    "df_mentions.columns.name = None\n",
    "df_authors = df_concepts_melted.groupby(['Concept', 'category'])['author'].nunique().reset_index().pivot(index='Concept', columns='category', values='author')\n",
    "df_authors['Total'] = df_authors.sum(axis=1)\n",
    "df_authors.columns.name = None\n",
    "\n",
    "# group melted df by country_code and Concept and number of concept\n",
    "dd=df_concepts_melted.groupby(['country_code', 'Concept'])['Concept'].count().rename('count').reset_index()\n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "merged = world.set_index(\"iso_a3\").join(dd.set_index(\"country_code\"),how=\"inner\")\n",
    "# where concept is nan, create new rows for all concepts with count 0\n",
    "# merged = merged.reset_index().melt(id_vars=['country', 'geometry'], value_vars=merged.columns[2:], value_name='count').dropna(subset=['count'])\n",
    "\n",
    "# get a unique mapping between document_id and document_name_y for the df_concepts_melted\n",
    "mapping = df_concepts_melted[['document_id', 'document_name_y', 'category','author']].drop_duplicates()\n",
    "# now apply this mapping to df_spans to create a new column with the document_name\n",
    "\n",
    "df_spans['processed_sentence']=df_spans['sentence'].apply(lambda x: ' '.join([word for word in x.split() if word not in (STOPWORDS)]))\n",
    "df_spans['normalised_text']=df_spans['text'].str.lower()\n",
    "df_spans = df_spans.merge(mapping, on=['document_id'], how='left')\n",
    "merged=merged.reset_index().rename(columns={'index': 'iso_a3'})\n",
    "# for every country in world, check if the concept is in merged. If not, add a row with count 0\n",
    "for country in world['iso_a3']:\n",
    "    for concept in merged['Concept'].unique():\n",
    "        if not merged[(merged['iso_a3']==country) & (merged['Concept']==concept)].empty:\n",
    "            continue\n",
    "        else:\n",
    "            merged = pd.concat([merged, world[world['iso_a3']==country].reset_index(drop=True).merge(pd.DataFrame({'Concept': concept, 'count': 0}, index=[0]), left_index=True, right_index=True)], ignore_index=True)\n",
    "\n",
    "\n",
    "merged = merged.rename(columns={'name': 'country'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-1'></a>\n",
    "# Introduction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "report_text = f\"\"\"\n",
    " This report contains summary statistics and visualisations for all identified mentions of {concept} within the Global Stocktake submissions, as of {date_of_nb}. It summarises the total number of mentions of {concept} and the number of documents these mentions come from,  broken down by Party and non-Party stakeholders. It also includes a full list of the Parties and non-Party stakeholders which mention {concept} within the Global Stocktake submissions, broken down by subtypes. A sample of the extracts where {concept} is mentioned is included below, with a link to the full set provided. The technical annex contains the methodology used to source the data for this report.\n",
    "\"\"\"\n",
    "display(Markdown(report_text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-2'></a>\n",
    "# Analysis by author type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_analysed_table = create_docs_table(df_concepts_melted)\n",
    "docs_analysed_table_melted = docs_analysed_table.reset_index().melt(id_vars=[\"index\"], var_name=\"stakeholder\", value_name=\"count\")\n",
    "chart = alt.Chart(docs_analysed_table_melted).mark_bar().encode(\n",
    "    x='index:N',\n",
    "    y='count:Q',\n",
    "    color='stakeholder:N',\n",
    "    order=alt.Order('stakeholder:N', sort='ascending')\n",
    ").properties(title=f\"Number of documents analysed by author type\", width=400, height=300)\n",
    "\n",
    "chart\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-2-2'></a>\n",
    "## Number of mentions of each concept split by Party/non-Party stakeholders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df_mentions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-2-3'></a>\n",
    "## Number of documents mentioning each concept split by Party and non-Party stakeholders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df_documents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-2-4'></a>\n",
    "## Number of authors mentioning each concept split by Party/non-Party stakeholders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df_authors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_percentages_stacked(df):\n",
    "    df=df.reset_index()\n",
    "    df['Non-Party_percentage'] = df['Non-Party'] / df['Total'] * 100\n",
    "    df['Party_percentage'] = df['Party'] / df['Total'] * 100\n",
    "\n",
    "    # Melt the DataFrame to have columns: Concept, Group, and Percentage\n",
    "    df_melted = df.melt(id_vars='Concept', value_vars=['Non-Party', 'Party'], var_name='Group', value_name='Percentage')\n",
    "\n",
    "    base = alt.Chart(df_melted).encode(\n",
    "        x=alt.X('Concept:N', title='Concept'),\n",
    "        y=alt.Y('Percentage:Q', title='Percentage', stack='normalize', axis=alt.Axis(format='%')),\n",
    "        color=alt.Color('Group:N', title='Group', scale=alt.Scale(scheme='tableau10')),\n",
    "        tooltip=['Concept', 'Group', 'Percentage']\n",
    "    )\n",
    "\n",
    "    # Create the bar chart\n",
    "    bar_chart = base.mark_bar().encode()\n",
    "\n",
    "    display(bar_chart)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-2-6'></a>\n",
    "## Percentage of documents mentioning each concept by Party/non-Party stakeholders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# number of unique documents mentioning each concept\n",
    "data_docs=(100*df_concepts_melted.groupby(['category','Concept']).document_id.nunique()/df_concepts_melted.groupby('category').document_id.nunique()).rename('Percentage').reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alt.Chart(data_docs).mark_bar().encode(\n",
    "    x=alt.X('category:O'),\n",
    "    y='Percentage:Q',\n",
    "    color='category:N',\n",
    "    column='Concept:N',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-2-7'></a>\n",
    "## Percentage of authors mentioning each concept by Party/non-Party stakeholders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# of all the Party/non-Party-authors in the corpus, what percentage have documents containing mentions of each concept?\n",
    "data_authors=(100*df_concepts_melted.groupby(['category','Concept']).author.nunique()/df_concepts_melted.groupby('category').author.nunique()).rename('Percentage').reset_index()\n",
    "# make sure chart has no x-axis labels\n",
    "chart=alt.Chart(data_authors).mark_bar().encode(\n",
    "    x=alt.X('category:O', axis=alt.Axis(labels=True)),\n",
    "    y='Percentage:Q',\n",
    "    color='category:N',\n",
    "    column='Concept:N',\n",
    ")\n",
    "chart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-3'></a>\n",
    "# Granular Breakdown of Concepts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "total_concept_mentions = df_spans.rename(columns={'type':'concept'}).groupby(['id', 'concept']).document_id.count().reset_index().rename(columns={'document_id':'count'})\n",
    "document_concept_mentions = df_spans.rename(columns={'type':'concept'}).groupby(['id', 'concept']).document_id.nunique().reset_index().rename(columns={'document_id':'count'})\n",
    "author_concept_mentions = df_spans.rename(columns={'type':'concept'}).groupby(['id', 'concept']).author.nunique().reset_index().rename(columns={'author':'count'})\n",
    "\n",
    "def plot_concept_mentions(data, title):\n",
    "    # Create a base chart\n",
    "    base_chart = alt.Chart(data).mark_bar().encode(\n",
    "        y=alt.Y('count:Q', title=title),\n",
    "        x=alt.X('id:N', sort='-y',axis=alt.Axis(title=None, labels=True)),\n",
    "        color=alt.Color('concept:N', scale=alt.Scale(scheme='category10')),\n",
    "        tooltip=['count:Q'],\n",
    "    ).properties(\n",
    "        width=200,\n",
    "        height=300,\n",
    "    )\n",
    "\n",
    "    # Create faceted chart\n",
    "    faceted_chart = base_chart.facet(\n",
    "        facet=alt.Facet('concept:N', title=None),\n",
    "        columns=2,\n",
    "        spacing=15,\n",
    "        title=title\n",
    "    ).resolve_scale(x='independent')\n",
    "\n",
    "    display(faceted_chart)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-3-1'></a>\n",
    "## Total Mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_concept_mentions(total_concept_mentions, 'Total mentions of each concept')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-3-2'></a>\n",
    "## Total Documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_concept_mentions(document_concept_mentions, 'Number of documents mentioning each concept')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-3-3'></a>\n",
    "## Total Authors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_concept_mentions(author_concept_mentions, 'Number of authors mentioning each concept')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-4'></a>\n",
    "# Geographical distribution of concepts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to create a choropleth map for a given concept\n",
    "def create_choropleth_map(merged, concept):\n",
    "    choropleth_map = (\n",
    "        alt.Chart(merged[merged['Concept'] == concept])\n",
    "        .mark_geoshape(stroke=\"black\", strokeWidth=1)\n",
    "        .encode(\n",
    "            color=alt.Color(\"count:Q\", scale=alt.Scale(scheme=\"viridis\")),\n",
    "            tooltip=[\"country:N\", \"count:Q\"],\n",
    "        )\n",
    "        .properties(width=800, height=400, title=f\"Number of Mentions of {concept} by Country\")\n",
    "    )\n",
    "    return choropleth_map\n",
    "\n",
    "# Iterate over the unique concepts and create a separate choropleth map for each\n",
    "unique_concepts = sorted(merged['Concept'].unique())\n",
    "for concept in unique_concepts:\n",
    "    choropleth_map = create_choropleth_map(merged, concept)\n",
    "    choropleth_map.display()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-5'></a>\n",
    "# Sample mentions of concepts\n",
    "\n",
    "Here is a sample of mentions of concepts in the documents. To see the full list, see here (TODO: add link to external Excel download)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get a unique mapping between document_id and document_name_y for the df_concepts_melted\n",
    "mapping = df_concepts_melted[['document_id', 'document_name_y', 'category']].drop_duplicates()\n",
    "# now apply this mapping to df_spans to create a new column with the document_name\n",
    "df_spans = df_spans.merge(mapping, on=['document_id'], how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_spans_sample = df_spans[['document_name_y', 'type','category', 'sentence']].dropna().sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-6'></a>\n",
    "# Word Co-Ocurrences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt', quiet=True);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_ngrams(df, concept, n, text_col=\"processed_sentence\"):\n",
    "    # Filter the DataFrame for the given concept\n",
    "    concept_df = df[df['type'] == concept]\n",
    "\n",
    "    # Tokenize the sentences and extract n-grams\n",
    "    tokens = [word_tokenize(sentence) for sentence in concept_df[text_col]]\n",
    "    ngram_list = [ngram for sentence in tokens for ngram in ngrams(sentence, n)]\n",
    "\n",
    "    # Filter out n-grams containing non-word characters\n",
    "    word_ngrams = [ngram for ngram in ngram_list if all(re.match(r'^\\w+$', word) for word in ngram)]\n",
    "\n",
    "    # Calculate the frequency distribution of n-grams\n",
    "    freq_dist = FreqDist(word_ngrams)\n",
    "\n",
    "    return freq_dist\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "concepts = df_spans.type.unique()\n",
    "\n",
    "# Set the number of top bigrams and trigrams to display\n",
    "num_top_ngrams = 10\n",
    "\n",
    "for concept in concepts:\n",
    "    display(Markdown(f\"## Top {num_top_ngrams} bigrams and trigrams in sentences relating to {concept.title()}\\n\"))\n",
    "\n",
    "    # Extract bigrams and trigrams for the given concept\n",
    "    bigrams_freq = extract_ngrams(df_spans, concept, n=2, text_col=\"processed_sentence\")\n",
    "    trigrams_freq = extract_ngrams(df_spans, concept, n=3, text_col=\"processed_sentence\")\n",
    "\n",
    "    # Create DataFrames for bigrams and trigrams\n",
    "    bigrams_df = pd.DataFrame(bigrams_freq.most_common(num_top_ngrams), columns=['Bigrams', 'Frequency'])\n",
    "    trigrams_df = pd.DataFrame(trigrams_freq.most_common(num_top_ngrams), columns=['Trigrams', 'Frequency'])\n",
    "\n",
    "    display(Markdown(f\"### Bigrams\\n\"))\n",
    "    display(bigrams_df)\n",
    "    display(Markdown(f\"### Trigrams\\n\"))\n",
    "    display(trigrams_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "infile=pd.read_excel(\"/home/stefan/PycharmProjects/global-stocktake/concepts/fossil-fuels/input.xlsx\", header=[0,1]);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "excel_string = infile.to_csv(sep='\\t', index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#, header=[0,1])\n",
    "# infile.columns = infile.columns.map(' - '.join)\n",
    "infile.columns = [' - '.join(col).strip() if 'Unnamed' not in col[1] else col[0] for col in infile.columns]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-7'></a>\n",
    "# Annex: Methodology"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(Markdown(f\"\"\"\n",
    "The documents within the Global Submissions Information Portal were searched for all mentions of {concept}. The documents are all automatically translated into English using a Google Translate API, and the full text of all documents are then searched and return mentions of {concept} within the translated or original text.\n",
    "\n",
    "To capture the variations of the expression of {concept} within the Global Stocktake submissions, the following input file was created (TODO: Provide link to input file).\"\"\"))\n",
    "\n",
    "display(infile)\n",
    "\n",
    "\n",
    "display(Markdown(F\"\"\"The root forms of the terms were used so that all variations of these listed terms were searched. For example, ‘technology’ would return ‘technologies’ and ‘technological’.\n",
    "\n",
    "Terms connected with a hyphen are also returned separately. For example, ‘coal-fired’ would return ‘coal-fired’ and ‘coal fired’.\"\"\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
    "import openai\n",
    "\n",
    "openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "def explain_excel_content(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an academic who provides intuitive explanations of complex concepts.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "\n",
    "    ],\n",
    "    temperature=0.0,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Describe the content of the Excel file\n",
    "# Replace this description with the actual content or structure of your Excel file\n",
    "excel_file = infile\n",
    "\n",
    "\n",
    "# Generate a prompt for the OpenAI API\n",
    "prompt = f\"Please provide a short intuitive explanation of the spacy linguistic rules in this copy and paste from a excel file. Assume the user doesn't have any linguistic knowledge: {excel_string}\"\n",
    "\n",
    "# Send the request to the OpenAI API\n",
    "explanation = explain_excel_content(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='section-8'></a>\n",
    "# Explanation of the linguistic rules using OpenAI GPT-4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display the explanation accounting for \\n\n",
    "display(Markdown(f\"{explanation}\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "This text appears to be a list of linguistic rules for categorizing different types of fossil fuels and their related terms. The rules are organized in a table format, with each row representing a specific rule. The first column indicates the general category (e.g., Oil, Gas, Coal, or Fossil fuel), and the subsequent columns provide information on how to identify and classify terms related to that category.\n\nThe rules use various linguistic features to classify terms, such as:\n\n1. LOWER: This feature checks if the term is in lowercase (e.g., \"oil\" or \"gas\").\n2. LEMMA: This feature checks the base form of a word (e.g., \"sand\" for \"sands\" or \"peatland\" for \"peatlands\").\n3. ORTH: This feature checks the spelling of a word (e.g., \"-\" for \"oil-fired\" or \"coal-water\").\n4. OP: This feature checks the presence of a specific character (e.g., \"?\" for \"oil-fired\" or \"coal-water\").\n5. IS_UPPER: This feature checks if the term is in uppercase (e.g., \"LNG\" or \"LPG\").\n\nFor example, the rule for \"Oil\" and \"oil\" in lowercase (Oil, oil, LOWER, oil) means that if the term \"oil\" is found in lowercase, it should be classified under the \"Oil\" category. Similarly, the rule for \"Gas\" and \"LNG\" in uppercase (Gas, LNG, LOWER, LNG, IS_UPPER, YES) means that if the term \"LNG\" is found in uppercase, it should be classified under the \"Gas\" category.\n\nIn summary, this list of linguistic rules helps to categorize and classify terms related to fossil fuels based on their spelling, capitalization, and base forms."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the explanation accounting for \\n\n",
    "display(Markdown(f\"{explanation}\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}