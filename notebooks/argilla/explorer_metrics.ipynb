{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating metrics for explorer runs\n",
    "\n",
    "Using [nervaluate](https://github.com/MantisAI/nervaluate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/Users/kalyan/Library/Caches/pypoetry/virtualenvs/global-stocktake-HXOiBphk-py3.9/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/Users/kalyan/Library/Caches/pypoetry/virtualenvs/global-stocktake-HXOiBphk-py3.9/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nervaluate in /Users/kalyan/Library/Caches/pypoetry/virtualenvs/global-stocktake-HXOiBphk-py3.9/lib/python3.9/site-packages (0.1.8)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/Users/kalyan/Library/Caches/pypoetry/virtualenvs/global-stocktake-HXOiBphk-py3.9/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/Users/kalyan/Library/Caches/pypoetry/virtualenvs/global-stocktake-HXOiBphk-py3.9/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/Users/kalyan/Library/Caches/pypoetry/virtualenvs/global-stocktake-HXOiBphk-py3.9/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/Users/kalyan/Library/Caches/pypoetry/virtualenvs/global-stocktake-HXOiBphk-py3.9/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install nervaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalyan/Library/Caches/pypoetry/virtualenvs/global-stocktake-HXOiBphk-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import glob\n",
    "import os\n",
    "import hashlib\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import argilla as rg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import spacy\n",
    "import math\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping from old to new IDs\n",
    "mapping_path = \"/Users/kalyan/Documents/CPR/unfccc-global-stocktake-documents/notebooks/old-to-new-dataset-mapping.csv\"\n",
    "mapping_df = pd.read_csv(mapping_path)\n",
    "\n",
    "ids_mapping = {\n",
    "    row[\"document_id_old\"]: row[\"document_id_new\"] for _, row in mapping_df.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/785 documents successfully mapped ids\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "DATASET_NAME = \"explorer-quality-testing\"\n",
    "\n",
    "rg.init(workspace=\"gst\", api_key=os.environ[\"ARGILLA_API_KEY\"])\n",
    "rg_dataset = rg.load(DATASET_NAME, query=\"status:Validated\")\n",
    "\n",
    "# List of subdirectories to include\n",
    "concepts = [\n",
    "    \"financial-flows\",\n",
    "    \"deforestation\",\n",
    "    \"vulnerable-groups\",\n",
    "    \"equity-and-just-transition\",\n",
    "    \"barriers-and-challenges\",\n",
    "    \"good-practice-and-opportunities\",\n",
    "]\n",
    "\n",
    "type_mapping = {\n",
    "    \"Good Practices and Opportunities\": \"Good Practice And Opportunities\",\n",
    "    \"Barriers and Challenges\": \"Barriers And Challenges\",\n",
    "    \"Equity And Justice\": \"Equity And Just Transition\",\n",
    "}\n",
    "\n",
    "\n",
    "def map_type(old_type: str) -> str:\n",
    "    \"\"\"Map type used in Argilla to any renamed types since the Argilla load\"\"\"\n",
    "    if old_type not in type_mapping:\n",
    "        return old_type\n",
    "\n",
    "    return type_mapping[old_type]\n",
    "\n",
    "\n",
    "def map_record_id(record):\n",
    "    \"\"\"Modify a TokenClassificationRecord in place to use new IDs\"\"\"\n",
    "\n",
    "    new_id = ids_mapping.get(record.metadata[\"document_id\"])\n",
    "\n",
    "    if new_id is None:\n",
    "        # print(f\"could not find ID {record.metadata['document_id']} in mapping\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    record.metadata[\"document_id\"] = new_id\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "mapped_documents = 0\n",
    "\n",
    "for idx, document in enumerate(rg_dataset):\n",
    "    if document.annotation:\n",
    "        document.annotation = [\n",
    "            (map_type(item[0]), item[1], item[2]) for item in document.annotation\n",
    "        ]\n",
    "\n",
    "    # # FIXME: we exclude annotations from Joe here as his labelling style was a bit different\n",
    "    # if document.annotation_agent == \"joe\":\n",
    "    #     document.metadata[\"document_id\"] = \"EXCLUDED\"\n",
    "\n",
    "    if map_record_id(document) is None:\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        document = map_record_id(document)\n",
    "        mapped_documents += 1\n",
    "\n",
    "\n",
    "print(f\"{mapped_documents}/{len(rg_dataset)} documents successfully mapped ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CPR dataset and add span annotations to token classification records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.opensearch.index_data import get_dataset_and_filter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1697/1697 [01:13<00:00, 23.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1679/1679 [02:00<00:00, 13.97it/s]\n",
      "1558docs [00:57, 27.05docs/s]\n"
     ]
    }
   ],
   "source": [
    "cpr_dataset, _ = get_dataset_and_filter_values(\n",
    "    Path(os.environ[\"DOCS_DIR_GST\"]),\n",
    "    Path(\n",
    "        \"/Users/kalyan/Documents/CPR/unfccc-global-stocktake-documents/CPR_UNFCCC_MASTER.csv\"\n",
    "    ),\n",
    "    Path(\"../../concepts\").absolute(),\n",
    "    limit=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1679/1679 [00:11<00:00, 143.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# create hash map between IDs and spans\n",
    "\n",
    "SPAN_TYPES = {\n",
    "    \"Financial Flows\",\n",
    "    \"Deforestation\",\n",
    "    \"Vulnerable Groups\",\n",
    "    \"Equity And Just Transition\",\n",
    "    \"Barriers And Challenges\",\n",
    "    \"Good Practice And Opportunities\",\n",
    "}\n",
    "\n",
    "doc_id_text_hash_span_map = dict()\n",
    "\n",
    "for doc in tqdm(cpr_dataset.documents):\n",
    "    if doc.text_blocks is None:\n",
    "        continue\n",
    "\n",
    "    for block in doc.text_blocks:\n",
    "        # We have to recreate the block text hash here as hashes aren't stored in argilla\n",
    "        # and we modify the text on argilla data load. This is replicating the transformation\n",
    "        # that happens in Argilla\n",
    "        text = block.to_string().replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
    "        text_hash = hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "        for span in block.spans:\n",
    "            if span.type.split(\"–\")[0].strip() not in SPAN_TYPES:\n",
    "                continue\n",
    "\n",
    "            span.type = span.type.split(\"–\")[0].strip()\n",
    "\n",
    "            doc_span_id = f\"{span.document_id}_{text_hash}\"\n",
    "\n",
    "            if doc_span_id in doc_id_text_hash_span_map:\n",
    "                doc_id_text_hash_span_map[doc_span_id].append(span)\n",
    "\n",
    "            else:\n",
    "                doc_id_text_hash_span_map[doc_span_id] = [span]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 785/785 [00:00<00:00, 17705.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argilla blocks found in CPR dataset: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Good Practice And Opportunities': 38,\n",
       " 'Barriers And Challenges': 39,\n",
       " 'Deforestation': 39,\n",
       " 'Equity And Just Transition': 21,\n",
       " 'Financial Flows': 43,\n",
       " 'Vulnerable Groups': 20}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add predictions to each Argilla record\n",
    "\n",
    "# Maps span type to records which predict only for that span type to deal with the fact that Argilla can't handle overlaps\n",
    "prediction_records = defaultdict(list)\n",
    "\n",
    "argilla_blocks_found_in_cpr_dataset = 0\n",
    "\n",
    "for record in tqdm(rg_dataset):\n",
    "    text_hash = hashlib.md5(record.text.encode(\"utf-8\")).hexdigest()\n",
    "    doc_span_id = f\"{record.metadata['document_id']}_{text_hash}\"\n",
    "\n",
    "    if doc_span_id in doc_id_text_hash_span_map:\n",
    "        argilla_blocks_found_in_cpr_dataset += 1\n",
    "\n",
    "        predictions = [\n",
    "            (span.type, span.start_idx, span.end_idx)\n",
    "            for span in doc_id_text_hash_span_map[doc_span_id]\n",
    "        ]\n",
    "        predictions = sorted(predictions, key=lambda x: x[0])\n",
    "\n",
    "        # add all predictions to argilla record\n",
    "        record.prediction = predictions\n",
    "\n",
    "        # create temp argilla records per span type\n",
    "        for span_type, span_predictions in itertools.groupby(\n",
    "            predictions, lambda x: x[0]\n",
    "        ):\n",
    "            record_copy = record.copy()\n",
    "            record_copy.prediction = list(span_predictions)\n",
    "            prediction_records[span_type].append(record_copy)\n",
    "\n",
    "print(f\"Argilla blocks found in CPR dataset: {argilla_blocks_found_in_cpr_dataset}\")\n",
    "support = {k: len(v) for k, v in prediction_records.items()}\n",
    "support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use nervaluate for performance stats measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nervaluate import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argilla_to_nervaluate(record):\n",
    "    return [{\"label\": item[0], \"start\": item[1], \"end\": item[2]} for item in record]\n",
    "\n",
    "\n",
    "ground_truth = [argilla_to_nervaluate(record.annotation) for record in rg_dataset]\n",
    "predictions = [argilla_to_nervaluate(record.prediction or []) for record in rg_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(ground_truth, predictions, SPAN_TYPES)\n",
    "results, results_per_tag = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate individual errors (per text block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps(a, b) -> bool:\n",
    "    \"\"\"Whether a and b have any overlap\"\"\"\n",
    "    if a[\"start\"] > b[\"start\"]:\n",
    "        return overlaps(b, a)\n",
    "    assert a[\"start\"] <= b[\"start\"]\n",
    "    return a[\"end\"] >= b[\"start\"]\n",
    "\n",
    "\n",
    "instance_level_results = []\n",
    "\n",
    "for idx in range(len(evaluator.true)):\n",
    "    # each item in evaluator.true and evaluator.pred is a list of dictionaries with the following structure\n",
    "    # {'label': 'Good Practice And Opportunities', 'start': 16, 'end': 29}\n",
    "\n",
    "    item_results = defaultdict(list)\n",
    "\n",
    "    for truth, pred in itertools.product(evaluator.true[idx], evaluator.pred[idx]):\n",
    "        if overlaps(truth, pred) and truth[\"label\"] != pred[\"label\"]:\n",
    "            item_results[\"incorrect\"].append({\"true\": truth, \"pred\": pred})\n",
    "\n",
    "    for truth in evaluator.true[idx]:\n",
    "        if not any(\n",
    "            (overlaps(truth, pred) and truth[\"label\"] == pred[\"label\"])\n",
    "            for pred in evaluator.pred[idx]\n",
    "        ):\n",
    "            item_results[\"missed\"].append(truth)\n",
    "\n",
    "    instance_level_results.append(item_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 text passages with 1 or more incorrect results \n",
      "\n",
      "We agree with the IPCC's Sixth Assessment report that \"Any further delay in concerted anticipatory global action on adaptation and mitigation will miss a brief and rapidly closing window of opportunity to secure a liveable and sustainable future for all.\" Urgent change is required in how we produce our electricity, heat our homes and travel.\n",
      "```\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 55, 'end': 253}\n",
      "- predicted: {'label': 'Good Practice And Opportunities', 'start': 190, 'end': 201}\n",
      "\n",
      "```\n",
      "\n",
      "UNEP adaptation gap report suggested adaptation costs \"in developing countries alone\" could reach $140-300bn in 2030, which echoes language in the Paris Agreement urging a \"balance between adaptation and mitigation\" finance. Extreme weather events and unimaginable destructions throughout the world are clear proof there is more we should do other than mitigation and adaptation i.e., recognize and compensate for loss and damage. There have been estimations that have placed the costs of loss and damage at $300-700bn by 2030, rising to $1.2tn per year by 2060. Huge climate finance is required to implement the scale of action demanded by the urgency of the climate crisis.\n",
      "```\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 37, 'end': 116}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 103, 'end': 108}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 37, 'end': 116}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 102, 'end': 103}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 37, 'end': 116}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 99, 'end': 102}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 37, 'end': 116}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 98, 'end': 99}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 431, 'end': 674}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 512, 'end': 513}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 431, 'end': 674}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 549, 'end': 553}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 431, 'end': 674}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 509, 'end': 512}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 431, 'end': 674}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 538, 'end': 539}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 431, 'end': 674}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 539, 'end': 544}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 431, 'end': 674}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 513, 'end': 518}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 431, 'end': 674}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 508, 'end': 509}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 431, 'end': 674}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 576, 'end': 583}\n",
      "\n",
      "- true: {'label': 'Barriers And Challenges', 'start': 431, 'end': 674}\n",
      "- predicted: {'label': 'Financial Flows', 'start': 545, 'end': 548}\n",
      "\n",
      "```\n",
      "\n",
      "62. For the forestry sector, the four mitigation actions focus on maintaining the existing forest and forest carbon stocks by preventing deforestation and forest degradation; expanding the forest and carbon sinks through afforestation, reforestation, agroforestry and the establishment of urban green landscapes; promoting and maintaining sustainable forest and non-timber forest products; and increasing the efficiency of forest resources. The Lao People's Democratic Republic reported potential emission reductions of 60,000-69,000 kt CO₂ eq to be achieved by maintaining existing forest and carbon sinks. Under this action, the Party intends to increase forest cover by 16.58 Mha by 2020, reduce slash and burn agriculture by 15 per cent by 2030, and ensure that 50 per cent of protected and conserved forest areas is well managed. The Party also aims to establish 500,000 ha plantations by 2020 and one park per community (with a population greater than 100,000) by 2030.\n",
      "```\n",
      "- true: {'label': 'Deforestation', 'start': 66, 'end': 439}\n",
      "- predicted: {'label': 'Barriers And Challenges', 'start': 126, 'end': 136}\n",
      "\n",
      "```\n",
      "\n",
      "Advances in the generation of information disaggregated by sex. In the 2018-2019 period, based on the recommendations for gender integration in the Fifth National Communication and the Third BUR, a process of analysis of the feasibility of gender integration in the INGEI was carried out. The objective of this process was to identify the possibility of obtaining population data, and from it, the disaggregation by sex of the sources that report to the INGEI. For this, a sectoral consultation was carried out that allowed us to have a first general knowledge about the viability of each sector with respect to this information. The conclusion was that although it is not possible to automatically generate emission data disaggregated by sex, there are differences between the categories reported in relation to the feasibility of doing so. As an intangible result, it must be expressed that this process allowed problematizing with the sectors that report to the INGEI about the relevance and potential of having this information, an aspect that may be considered in new information generation designs.\n",
      "```\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 122, 'end': 140}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 122, 'end': 128}\n",
      "\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 240, 'end': 258}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 240, 'end': 246}\n",
      "\n",
      "```\n",
      "\n",
      "For nearly four decades, Iceland's official development cooperation has placed particular focus on the sustainable utilisation of natural resources, including fisheries and renewable energy. This has been grounded on Iceland's experience and expertise in utilizing its own resources for its social, economic and human development. This legacy is maintained in Iceland's Strategy for International Development Cooperation, which identifies three priority areas: sustainable use of natur resources, social infrastructure and peacebuilding, with gender equality and environmental sustainability as special crosscutting themes.\n",
      "```\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 543, 'end': 558}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 543, 'end': 549}\n",
      "\n",
      "```\n",
      "\n",
      "The global energy transition offers an unprecedented opportunity to transform the energy sector in all aspects. The transition towards a renewable, distributed, decarbonized energy system is creating an array of social and economic benefits, including growing employment. In the report, Renewable Energy: A Gender Perspective, IRENA estimates that the number of jobs in the sector could increase from 10.3 million in 2017 to nearly 29 million in 2050. The sector offers diverse opportunities along the value chain, requiring different skill sets and talents. A key pillar of the energy should be to ensure that the opportunities it creates are equally accessible, and the benefits it bestows, equitably distributed.\n",
      "```\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 307, 'end': 325}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 307, 'end': 313}\n",
      "\n",
      "```\n",
      "\n",
      "Recognizing social and cultural contexts and specificities, including the different roles, knowledge systems and capacities of men and women, enables the adoption of a targeted approach to gender-responsive adaptation in each individual adaptation context.\n",
      "```\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 0, 'end': 255}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 189, 'end': 195}\n",
      "\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 0, 'end': 255}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 135, 'end': 140}\n",
      "\n",
      "```\n",
      "\n",
      "Based on these findings, recommendations to address both gender inequality and the empowerment of women are proposed. Key recommendations include:\n",
      "```\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 57, 'end': 74}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 57, 'end': 63}\n",
      "\n",
      "```\n",
      "\n",
      "Therefore, some of the issues that must be paid attention to enhance the positive gender impact in the transition towards a low carbon economy, are related to the achievement of a balanced representation between women and men and their full, equal and significant at all levels, both in the governing bodies and in the staff. One of the drawbacks for monitoring this aspect is the lack of systematic periodic data disaggregated by sex and gender-specific indicators. In order to effectively apply the gender perspective, it is necessary, first of all, to have an x-ray of the situation and evolution of women and men in the sectors involved, having the necessary data for the analysis of vertical and horizontal gender segregation. in each sector, as well as the factors related to the gaps detected.\n",
      "```\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 82, 'end': 113}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 82, 'end': 88}\n",
      "\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 501, 'end': 519}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 501, 'end': 507}\n",
      "\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 712, 'end': 730}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 712, 'end': 718}\n",
      "\n",
      "```\n",
      "\n",
      "Enhancing Gender-Responsive Adaptation Action\n",
      "```\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 10, 'end': 27}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 10, 'end': 16}\n",
      "\n",
      "```\n",
      "\n",
      "64. Kuwait reported information on constraints and gaps, and related financial, technical and capacity-building needs in accordance with decision 2/CP.17, annex III, paragraph 14. In its BUR, Kuwait identified several technical, institutional, legislative and financial constraints at various levels, including lack of accurate databases; inadequate analysis, collection and dissemination of data; limited cooperation between agencies providing GHG inventory data; and lack of familiarity with methods and tools for quantifying climate change impacts in vulnerable sectors. Kuwait also reported key capacity gaps, including lack of access to long-term climate information and uncertainties when conducting vulnerability and adaptation assessments; inadequate institutional and technical capacities to plan and implement adaptation measures; and limited funding for climate change related research. The Party reported that its capacity-building needs relate to GHG inventory preparation, analysis of mitigation opportunities and vulnerability assessment, in addition to the areas identified in its NC2.\n",
      "```\n",
      "- true: {'label': 'Financial Flows', 'start': 260, 'end': 281}\n",
      "- predicted: {'label': 'Barriers And Challenges', 'start': 270, 'end': 281}\n",
      "\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 672, 'end': 839}\n",
      "- predicted: {'label': 'Barriers And Challenges', 'start': 748, 'end': 758}\n",
      "\n",
      "```\n",
      "\n",
      "Address gender considerations throughout NAPS\n",
      "```\n",
      "- true: {'label': 'Equity And Just Transition', 'start': 8, 'end': 29}\n",
      "- predicted: {'label': 'Vulnerable Groups', 'start': 8, 'end': 14}\n",
      "\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# incorrect results - misclassified.\n",
    "# note sometimes these could be to do with the fact that we can't label overlapping spans in Argilla\n",
    "incorrect_results = [\n",
    "    (rg_dataset[idx], result[\"incorrect\"])\n",
    "    for (idx, result) in enumerate(instance_level_results)\n",
    "    if \"incorrect\" in result\n",
    "]\n",
    "print(\n",
    "    str(len(incorrect_results)) + \" text passages with 1 or more incorrect results \\n\"\n",
    ")\n",
    "\n",
    "\n",
    "def format_incorrect_spans(incorrect_spans) -> str:\n",
    "    formatted_spans = []\n",
    "\n",
    "    for item in incorrect_spans:\n",
    "        formatted_spans.append(\n",
    "            f\"\"\"- true: {item[\"true\"]}\n",
    "- predicted: {item[\"pred\"]}\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(formatted_spans)\n",
    "\n",
    "\n",
    "for rg_record, incorrect_spans in incorrect_results:\n",
    "    # print(f\"id: {rg_record.id}\")\n",
    "    print(rg_record.text)\n",
    "    print(\n",
    "        f\"\"\"```\n",
    "{format_incorrect_spans(incorrect_spans)}\n",
    "```\"\"\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missed results - in labels but with no annotation\n",
    "missed_results = [\n",
    "    {\"text\": rg_dataset[idx].text, \"spans\": result[\"missed\"]}\n",
    "    for (idx, result) in enumerate(instance_level_results)\n",
    "    if \"missed\" in result\n",
    "]\n",
    "\n",
    "for result in missed_results:\n",
    "    span_label_text_mapping = defaultdict(list)\n",
    "\n",
    "    for span in result[\"spans\"]:\n",
    "        span_label_text_mapping[span[\"label\"]].append(\n",
    "            result[\"text\"][span[\"start\"] : span[\"end\"]]\n",
    "        )\n",
    "\n",
    "    # span_text = [result['text'][span['start']:span['end']] for span in result[\"spans\"]]\n",
    "    result[\"span_text\"] = {k: \"|\".join(v) for k, v in span_label_text_mapping.items()}\n",
    "\n",
    "\n",
    "missing_df = pd.DataFrame(missed_results).drop(columns={\"spans\"})\n",
    "missing_df = pd.concat(\n",
    "    [missing_df, missing_df[\"span_text\"].apply(pd.Series).fillna(\"\")], axis=1\n",
    ").drop(columns={\"span_text\"})\n",
    "\n",
    "missing_df.to_csv(\"./data/missing_explorer_annotations_post_bonn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - any overlap between prediction and actual\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>partial</th>\n",
       "      <th>missed</th>\n",
       "      <th>spurious</th>\n",
       "      <th>possible</th>\n",
       "      <th>actual</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Financial Flows</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.35</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deforestation</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barriers And Challenges</th>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity And Just Transition</th>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.43</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good Practice And Opportunities</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vulnerable Groups</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.54</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 correct  incorrect  partial  missed  \\\n",
       "Financial Flows                     40.0        1.0      0.0    46.0   \n",
       "Deforestation                       62.0        1.0      0.0    40.0   \n",
       "Barriers And Challenges             27.0        3.0      0.0    25.0   \n",
       "Equity And Just Transition          28.0       10.0      0.0    46.0   \n",
       "Good Practice And Opportunities     30.0        0.0      0.0    25.0   \n",
       "Vulnerable Groups                   19.0        0.0      0.0    28.0   \n",
       "\n",
       "                                 spurious  possible  actual  precision  \\\n",
       "Financial Flows                     102.0      87.0   143.0       0.28   \n",
       "Deforestation                        37.0     103.0   100.0       0.62   \n",
       "Barriers And Challenges              20.0      55.0    50.0       0.54   \n",
       "Equity And Just Transition            7.0      84.0    45.0       0.62   \n",
       "Good Practice And Opportunities      20.0      55.0    50.0       0.60   \n",
       "Vulnerable Groups                     5.0      47.0    24.0       0.79   \n",
       "\n",
       "                                 recall    f1  support  \n",
       "Financial Flows                    0.46  0.35       43  \n",
       "Deforestation                      0.60  0.61       39  \n",
       "Barriers And Challenges            0.49  0.51       39  \n",
       "Equity And Just Transition         0.33  0.43       21  \n",
       "Good Practice And Opportunities    0.55  0.57       38  \n",
       "Vulnerable Groups                  0.40  0.54       20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results, strict - exact boundary match between prediction and actual\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>partial</th>\n",
       "      <th>missed</th>\n",
       "      <th>spurious</th>\n",
       "      <th>possible</th>\n",
       "      <th>actual</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Financial Flows</th>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deforestation</th>\n",
       "      <td>26.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barriers And Challenges</th>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity And Just Transition</th>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.22</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good Practice And Opportunities</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vulnerable Groups</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 correct  incorrect  partial  missed  \\\n",
       "Financial Flows                      8.0       33.0      0.0    46.0   \n",
       "Deforestation                       26.0       37.0      0.0    40.0   \n",
       "Barriers And Challenges             12.0       18.0      0.0    25.0   \n",
       "Equity And Just Transition          14.0       24.0      0.0    46.0   \n",
       "Good Practice And Opportunities     20.0       10.0      0.0    25.0   \n",
       "Vulnerable Groups                    9.0       10.0      0.0    28.0   \n",
       "\n",
       "                                 spurious  possible  actual  precision  \\\n",
       "Financial Flows                     102.0      87.0   143.0       0.06   \n",
       "Deforestation                        37.0     103.0   100.0       0.26   \n",
       "Barriers And Challenges              20.0      55.0    50.0       0.24   \n",
       "Equity And Just Transition            7.0      84.0    45.0       0.31   \n",
       "Good Practice And Opportunities      20.0      55.0    50.0       0.40   \n",
       "Vulnerable Groups                     5.0      47.0    24.0       0.38   \n",
       "\n",
       "                                 recall    f1  support  \n",
       "Financial Flows                    0.09  0.07       43  \n",
       "Deforestation                      0.25  0.26       39  \n",
       "Barriers And Challenges            0.22  0.23       39  \n",
       "Equity And Just Transition         0.17  0.22       21  \n",
       "Good Practice And Opportunities    0.36  0.38       38  \n",
       "Vulnerable Groups                  0.19  0.25       20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We only want ent_type (any overlap between ground truth and prediction for an entity) or exact (exact boundaries and matching type) for each span type\n",
    "\n",
    "ner_results_ent_type = dict()\n",
    "ner_results_strict = dict()\n",
    "\n",
    "for span_type, results in results_per_tag.items():\n",
    "    ner_results_ent_type[span_type] = results[\"ent_type\"]\n",
    "    ner_results_strict[span_type] = results[\"strict\"]\n",
    "\n",
    "print(\"Results - any overlap between prediction and actual\")\n",
    "results_df_ent_type = pd.DataFrame(ner_results_ent_type).T\n",
    "results_df_ent_type[\"support\"] = pd.Series(support)\n",
    "display(results_df_ent_type.round(2))\n",
    "\n",
    "print()\n",
    "print(\"Results, strict - exact boundary match between prediction and actual\")\n",
    "results_df_strict = pd.DataFrame(ner_results_strict).T\n",
    "results_df_strict[\"support\"] = pd.Series(support)\n",
    "display(results_df_strict.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results to tables for methodology\n",
    "\n",
    "`ent_type`: precision, recall, f1, support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barriers And Challenges\n",
      "|   Precision |   Recall |   F1 |   Support |\n",
      "|------------:|---------:|-----:|----------:|\n",
      "|        0.54 |     0.49 | 0.51 |        39 |\n",
      "Deforestation\n",
      "|   Precision |   Recall |   F1 |   Support |\n",
      "|------------:|---------:|-----:|----------:|\n",
      "|        0.62 |      0.6 | 0.61 |        39 |\n",
      "Equity And Just Transition\n",
      "|   Precision |   Recall |   F1 |   Support |\n",
      "|------------:|---------:|-----:|----------:|\n",
      "|        0.62 |     0.33 | 0.43 |        21 |\n",
      "Financial Flows\n",
      "|   Precision |   Recall |   F1 |   Support |\n",
      "|------------:|---------:|-----:|----------:|\n",
      "|        0.28 |     0.46 | 0.35 |        43 |\n",
      "Good Practice And Opportunities\n",
      "|   Precision |   Recall |   F1 |   Support |\n",
      "|------------:|---------:|-----:|----------:|\n",
      "|         0.6 |     0.55 | 0.57 |        38 |\n",
      "Vulnerable Groups\n",
      "|   Precision |   Recall |   F1 |   Support |\n",
      "|------------:|---------:|-----:|----------:|\n",
      "|        0.79 |      0.4 | 0.54 |        20 |\n"
     ]
    }
   ],
   "source": [
    "for concept, row in pd.DataFrame(results_df_ent_type).sort_index().iterrows():\n",
    "    concept_table = row[[\"precision\", \"recall\", \"f1\", \"support\"]].rename(\n",
    "        lambda i: i.title()\n",
    "    )\n",
    "    concept_table[[\"Precision\", \"Recall\", \"F1\"]] = concept_table[\n",
    "        [\"Precision\", \"Recall\", \"F1\"]\n",
    "    ].round(2)\n",
    "\n",
    "    print(concept)\n",
    "    print(pd.DataFrame(concept_table).T.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry_kernel",
   "language": "python",
   "name": "poetry_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
